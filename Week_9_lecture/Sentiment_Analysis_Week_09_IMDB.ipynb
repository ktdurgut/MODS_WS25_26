{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Ltum5ATzP4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)  # Set seed for NumPy\n",
    "random.seed(42) # Set seed for random module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D2Lcyxm3yr9"
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset contains tweets about different Airlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjRXt9kW3yr-"
   },
   "source": [
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkZIDbVJ3yr-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Loading the data from a csv file\n",
    "tweets = pd.read_csv(\"https://raw.githubusercontent.com/kbrennig/MODS_WS25_26/refs/heads/main/data/airlinetweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEw4DSv13yr_"
   },
   "source": [
    "### Display document\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1730729547098,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "ExVrJRPr3yr_",
    "outputId": "cbd7d124-8e7e-4da6-8135-6465a117b57a"
   },
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iNVEVqk3ysA"
   },
   "source": [
    "## Preprocessing\n",
    "Since unstructured data doesn't have an inherent and consistent structure we have to perform some preprocessing steps in order to make the data usable for the computer.\n",
    "One thing to keep in mind is that the more preprocessing we perform the more information we lose, but the basic methods we are using here require it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ZKKhND3ysA"
   },
   "source": [
    "### Tokenize documents\n",
    "First, we tokenize the texts. This means we transform the texts from one long string to a list of tokens. Additionally we also start removing unwanted characters (e.g punctuation between sentences, numbers, etc.).\n",
    "For a full list and explanation of the used parameters you can have a look at the documentation.\n",
    "\n",
    "### Stem all words\n",
    "After tokenizing the texts we perform stemming (alternatively lemmatization could be performed). Stemming reduces every word to its stem.\n",
    "The stemmer we use here is the Porter Stemmer.\n",
    "\n",
    "### Remove stopwords\n",
    "Finally we remove words that don't contain real meaning and are commonly used (e.g. 'this', 'the', 'a', etc.).\n",
    "\n",
    "Run the code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730729547098,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "H57M6Gr93ysA",
    "outputId": "fb169ca6-e1c0-4739-e7d3-b2bfe2b4c429"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Download the necessary nltk resource\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # create stemmer object\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "    # stem each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # get list of stopwords in English\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # remove stopwords\n",
    "    filtered_tokens = [token for token in stemmed_tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    # remove punctuation\n",
    "    filtered_tokens_nopunct = [token for token in filtered_tokens if token not in string.punctuation]\n",
    "\n",
    "    return filtered_tokens_nopunct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PDDeqId3ysB"
   },
   "source": [
    "## Apply preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 43441,
     "status": "ok",
     "timestamp": 1730729590537,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "-Jyd4YuU3ysB",
    "outputId": "169a78ec-4330-4b39-b955-2dfc93b459c1"
   },
   "outputs": [],
   "source": [
    "tweets['tokens'] = tweets['text'].apply(preprocess)\n",
    "tweets.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy-9wov43ysC"
   },
   "source": [
    "## Dictionary-Based Sentiment Analysis\n",
    "`Dictionary-based Sentiment Analysis` works by looking up the sentiment of each word occurring in a text in a `sentiment dictionary`. Afterwards the single sentiment scores are summed up to evaluate the text's sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv--FV5p3ysC"
   },
   "source": [
    "### Load NRC sentiment dictionary\n",
    "We use the NRC sentiment dictionary. This dictionary contains ten classes: anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise and trust.\n",
    "Currently we are only interested in positive and negative words.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGMkbdhR3ysC"
   },
   "outputs": [],
   "source": [
    "# Load NRC Emotion Lexicon\n",
    "nrc_df = pd.read_csv('https://raw.githubusercontent.com/kbrennig/MODS_WS25_26/refs/heads/main/data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None, names=['word', 'emotion', 'association'])\n",
    "\n",
    "# Filter out rows where association is 0\n",
    "nrc_df = nrc_df[nrc_df['association'] == 1]\n",
    "\n",
    "# Define positive and negative emotion categories\n",
    "positive_emotions = {'positive'}\n",
    "negative_emotions = {'negative'}\n",
    "\n",
    "# Filter words by emotion category and collect unique words for each sentiment orientation\n",
    "positive_words = nrc_df[nrc_df['emotion'].isin(positive_emotions)]['word'].unique()\n",
    "negative_words = nrc_df[nrc_df['emotion'].isin(negative_emotions)]['word'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh2dN7Ul3ysC"
   },
   "source": [
    "### Sample from dictionary\n",
    "We can look at an excerpt of the positive words contained in the dictionary.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730729590537,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "_Xqz4inW3ysC",
    "outputId": "16a95cdd-bdac-4c14-fdc5-9d393217ed07"
   },
   "outputs": [],
   "source": [
    "positive_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsuBrvzo3ysC"
   },
   "source": [
    "### Stem the positive and negative dictionaries\n",
    "The tokens in the dictionary aren't stemmed per default. Since we stemmed the tokens in our data, we also stem the positive and negative words in the dictionary.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbXXfmYi3ysC"
   },
   "outputs": [],
   "source": [
    "# Initialize the Porter stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# Stem the words in each list\n",
    "positive_words_stemmed = [stemmer.stem(word) for word in positive_words]\n",
    "negative_words_stemmed = [stemmer.stem(word) for word in negative_words]\n",
    "\n",
    "\n",
    "positive_words_stemmed[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDM4Bx2y3ysC"
   },
   "source": [
    "### Look-up remaining tokens in NRC dictionary and transform results to data frame\n",
    "If you want to perform the analysis with the unstemmed tokens you can copy the needed code parts to the summary section and adjust the input_data and remove the stemming from the preprocessing to use the unstemmed tokens. Additionally you will have to set stemmed_dict = False.\n",
    "\n",
    "Which procedure yields more accurate results and what do you believe to be the reason for the outcome?\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1730729591315,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "MWKuN0z5Zw35",
    "outputId": "b5fc1872-0911-4e4c-ce6b-dd132aef9421"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with both stemmed and unstemmed words for sentiment analysis\n",
    "sentiment_dict = {\n",
    "    'positive': list(positive_words),\n",
    "    'negative': list(negative_words),\n",
    "    'positive_stemmed': positive_words_stemmed,\n",
    "    'negative_stemmed': negative_words_stemmed\n",
    "}\n",
    "\n",
    "def sentiment_lookup(tokens, sentiment_dict, stemmed_dict=True):\n",
    "    if stemmed_dict:\n",
    "        # Use stemmed versions of the dictionary\n",
    "        positive_words = sentiment_dict['positive_stemmed']\n",
    "        negative_words = sentiment_dict['negative_stemmed']\n",
    "    else:\n",
    "        # Use original versions of the dictionary\n",
    "        positive_words = sentiment_dict['positive']\n",
    "        negative_words = sentiment_dict['negative']\n",
    "    \n",
    "    # Count positive and negative word matches\n",
    "    positive_count = sum(1 for token in tokens if token in positive_words)\n",
    "    negative_count = sum(1 for token in tokens if token in negative_words)\n",
    "    \n",
    "    return positive_count, negative_count\n",
    "\n",
    "tweets_toks_stemmed = tweets['tokens']\n",
    "\n",
    "# Perform lookup with stemmed dictionary\n",
    "results = [sentiment_lookup(tweets, sentiment_dict, stemmed_dict=True) for tweets in tweets_toks_stemmed]\n",
    "df_results = pd.DataFrame(results, columns=['positive_count', 'negative_count'])\n",
    "print(\"Results with Stemmed Dictionary:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPHK0id3ysC"
   },
   "source": [
    "### Calculate overall sentiment score\n",
    "After looking up the sentiment for the remaining tokens of each text we can now aggregate them by simply subtracting the number of negative words from the number of positive words found.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1730730262165,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "RwzHC64S3ysD",
    "outputId": "599d06d9-ae47-4069-dc1e-f3a3eaf09721"
   },
   "outputs": [],
   "source": [
    "# Calculate sentiment algorithm score (positive - negative)\n",
    "df_results['sentiment_algo_score'] = df_results['positive_count'] - df_results['negative_count']\n",
    "\n",
    "# Print the results with sentiment scores\n",
    "print(\"Results DataFrame:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eyV-djH3ysD"
   },
   "source": [
    "### Scale sentiment score by number of emotional words in a tweet\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "_aLRPXe-3ysD",
    "outputId": "f1a27fc6-c80b-4491-a735-33c4bd02a345"
   },
   "outputs": [],
   "source": [
    "df_results['sentiment_algo_scaled'] = df_results['sentiment_algo_score'] / (df_results['positive_count'] + df_results['negative_count'])\n",
    "df_results['sentiment_algo_scaled'].fillna(0, inplace=True)\n",
    "df_results['sentiment_algo_scaled'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVW_KkH3ysD"
   },
   "source": [
    "### Calculate binary sentiment label\n",
    "Similarly to classification we still have to decide which label to assign to each instance because until now we only have calculated their sentiment scores. Because we scaled the scores in the previous cell we can infer that scores greater than 0 indicate a positive sentiment and otherwise a negative sentiment.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "dEVHjnla3ysD",
    "outputId": "b29c45c8-84fe-4938-aa61-c464e4573d10"
   },
   "outputs": [],
   "source": [
    "df_results['sentiment_algo_binary'] = ['positive' if x > 0 else 'negative' for x in df_results['sentiment_algo_scaled']]\n",
    "df_results['sentiment_algo_binary'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXdANuDp3ysD"
   },
   "source": [
    "### Show distribution of human sentiment lables\n",
    "As a reference we can also display the ground truth distribution of positive and negative tweets. We can see that our model predicts a lot more positive tweets than contained in the dataset. (What could be a possible reason?)\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "0psY1-8V3ysD",
    "outputId": "d33b7c0c-c632-457e-f79f-743eaa52af58"
   },
   "outputs": [],
   "source": [
    "tweets['sentiment_human'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xni3qqmP3ysD"
   },
   "source": [
    "### Evaluate accuracy with human sentiment lables as ground truth\n",
    "Since the task at hand is classification (the only difference lies in the type of input data) we can evaluate our model in the same way as we did before.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gmmY_rWfMAn"
   },
   "outputs": [],
   "source": [
    "tweets_df_sent, results_df_bin = pd.DataFrame(tweets['sentiment_human']), pd.DataFrame(df_results['sentiment_algo_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1730731412830,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "s53MwZN1aVwB",
    "outputId": "5e4fff19-61f2-41cd-b5bd-ecb5f196a3e6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Compute accuracy\n",
    "accuracy = accuracy_score(tweets_df_sent['sentiment_human'], results_df_bin['sentiment_algo_binary'])\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Step 2: Compute confusion matrix and display it\n",
    "ConfusionMatrixDisplay.from_predictions(tweets_df_sent['sentiment_human'], results_df_bin['sentiment_algo_binary'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
