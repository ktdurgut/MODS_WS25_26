{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V-Ltum5ATzP4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)  # Set seed for NumPy\n",
    "random.seed(42) # Set seed for random module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWvxWzdt3yr8"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "So far we have only worked with what we call \"structured\" data, meaning the information was always stored in a tabular form where each instance (row) contained the same properties (columns). However, estimates suggest that about 80% of today's data is unstructured.\n",
    "\n",
    "Unlike structured data, which is tidy and mostly numeric in content, unstructured data is mainly textual or visual and, therefore, messy. The task of extracting knowledge from text documents, known as text analysis or natural language understanding, is highly complex and still limited by the ability of computers to understand the subtleties of human languages.\n",
    "\n",
    "One popular task in natural language processing (NLP) is `Sentiment Analysis`, which tries to extract the sentiment (e.g., positive, negative, etc.) of a given text (e.g., tweet).\n",
    "\n",
    "In this weeks tutorial we will start working with textual data, go through the necessary `Preprocessing` steps for the computer to be able to understand the information and lastly apply `dictionary-based Sentiment Analysis` to the texts in order to extract their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D2Lcyxm3yr9"
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use contains movie reviews from IMDB. Initially the data is stored as a dataframe with three columns (id, sentiment_human, text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjRXt9kW3yr-"
   },
   "source": [
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkZIDbVJ3yr-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Loading the data from a csv file\n",
    "reviews = pd.read_csv(\"https://raw.githubusercontent.com/kbrennig/MODS_WS25_26/refs/heads/main/data/imdb_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEw4DSv13yr_"
   },
   "source": [
    "### Display Document\n",
    "\n",
    "First of all, let's have a look at the raw data. The raw data contains an ID, a human sentiment (positive or negative), and the corresponding review text.\n",
    "\n",
    "Run the code below to get first insights on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1730729547098,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "ExVrJRPr3yr_",
    "outputId": "cbd7d124-8e7e-4da6-8135-6465a117b57a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_human</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>positive</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>positive</td>\n",
       "      <td>\\\"The Classic War of the Worlds\\\" by Timothy H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>negative</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>positive</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id sentiment_human                                               text\n",
       "0  5814_8        positive  With all this stuff going down at the moment w...\n",
       "1  2381_9        positive  \\\"The Classic War of the Worlds\\\" by Timothy H...\n",
       "2  7759_3        negative  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4        negative  It must be assumed that those who praised this...\n",
       "4  9495_8        positive  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iNVEVqk3ysA"
   },
   "source": [
    "## Preprocessing\n",
    "Since unstructured data doesn't have an inherent and consistent structure we have to perform some preprocessing steps in order to make the data usable for the computer.\n",
    "One thing to keep in mind is that the more preprocessing we perform the more information we lose, but the basic methods we are using here require it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1ZKKhND3ysA"
   },
   "source": [
    "### Tokenize documents\n",
    "First, we tokenize the texts. This means we transform the texts from one long string to a list of tokens. Additionally we also start removing unwanted characters (e.g punctuation between sentences, numbers, etc.).\n",
    "For a full list and explanation of the used parameters you can have a look at the documentation.\n",
    "\n",
    "### Stem all words\n",
    "After tokenizing the texts we perform stemming (alternatively lemmatization could be performed). Stemming reduces every word to its stem.\n",
    "The stemmer we use here is the Porter Stemmer.\n",
    "\n",
    "### Remove stopwords\n",
    "Finally we remove words that don't contain real meaning and are commonly used (e.g. 'this', 'the', 'a', etc.).\n",
    "\n",
    "Run the code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730729547098,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "H57M6Gr93ysA",
    "outputId": "fb169ca6-e1c0-4739-e7d3-b2bfe2b4c429"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/katharinabrennig/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/katharinabrennig/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/katharinabrennig/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Download the necessary nltk resource\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "#Define function with all necessary preprocessing steps for our IMDB reviews.\n",
    "def preprocess(text):\n",
    "    # tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # create stemmer object\n",
    "    stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "    # stem each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # get list of stopwords in English\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # remove stopwords\n",
    "    filtered_tokens = [token for token in stemmed_tokens if token.lower() not in stopwords]\n",
    "    \n",
    "    # remove punctuation\n",
    "    filtered_tokens_nopunct = [token for token in filtered_tokens if token not in string.punctuation]\n",
    "\n",
    "    return filtered_tokens_nopunct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PDDeqId3ysB"
   },
   "source": [
    "## Apply preprocessing\n",
    "\n",
    "After defining the different preprocessing steps, we now apply these preprocessing steps to our IMDB reviews. Running the code below we apply the preprocess function to the \"text\" column of our data and save the new preprocessed reviews as a new column in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 43441,
     "status": "ok",
     "timestamp": 1730729590537,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "-Jyd4YuU3ysB",
    "outputId": "169a78ec-4330-4b39-b955-2dfc93b459c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                            5814_8\n",
       "sentiment_human                                             positive\n",
       "text               With all this stuff going down at the moment w...\n",
       "tokens             [thi, stuff, go, moment, mj, 've, start, liste...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['tokens'] = reviews['text'].apply(preprocess)\n",
    "\n",
    "#show tokens for the first review in our dataset to get some insights\n",
    "reviews.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment_human</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>positive</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>[thi, stuff, go, moment, mj, 've, start, liste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>positive</td>\n",
       "      <td>\\\"The Classic War of the Worlds\\\" by Timothy H...</td>\n",
       "      <td>['', classic, war, worlds\\, '', timothi, hine,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>negative</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>[film, start, manag, nichola, bell, give, welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>[must, assum, prais, thi, film, '', greatest, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>positive</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>[superbl, trashi, wondrous, unpretenti, 80, 's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id sentiment_human                                               text  \\\n",
       "0  5814_8        positive  With all this stuff going down at the moment w...   \n",
       "1  2381_9        positive  \\\"The Classic War of the Worlds\\\" by Timothy H...   \n",
       "2  7759_3        negative  The film starts with a manager (Nicholas Bell)...   \n",
       "3  3630_4        negative  It must be assumed that those who praised this...   \n",
       "4  9495_8        positive  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [thi, stuff, go, moment, mj, 've, start, liste...  \n",
       "1  ['', classic, war, worlds\\, '', timothi, hine,...  \n",
       "2  [film, start, manag, nichola, bell, give, welc...  \n",
       "3  [must, assum, prais, thi, film, '', greatest, ...  \n",
       "4  [superbl, trashi, wondrous, unpretenti, 80, 's...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show review data with new column tokens\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy-9wov43ysC"
   },
   "source": [
    "## Dictionary-Based Sentiment Analysis\n",
    "`Dictionary-based Sentiment Analysis` works by looking up the sentiment of each word occurring in a text in a `sentiment dictionary`. Afterwards the single sentiment scores are summed up to evaluate the text's sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv--FV5p3ysC"
   },
   "source": [
    "### Load NRC sentiment dictionary\n",
    "We use the NRC sentiment dictionary. This dictionary contains ten classes: anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise and trust.\n",
    "Currently we are only interested in positive and negative words.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGMkbdhR3ysC"
   },
   "outputs": [],
   "source": [
    "# Load NRC Emotion Lexicon\n",
    "nrc_df = pd.read_csv('https://raw.githubusercontent.com/kbrennig/MODS_WS25_26/refs/heads/main/data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', sep='\\t', header=None, names=['word', 'emotion', 'association'])\n",
    "\n",
    "# Filter out rows where association is 0\n",
    "nrc_df = nrc_df[nrc_df['association'] == 1]\n",
    "\n",
    "# Define positive and negative emotion categories\n",
    "positive_emotions = {'positive'}\n",
    "negative_emotions = {'negative'}\n",
    "\n",
    "# Filter words by emotion category and collect unique words for each sentiment orientation\n",
    "positive_words = nrc_df[nrc_df['emotion'].isin(positive_emotions)]['word'].unique()\n",
    "negative_words = nrc_df[nrc_df['emotion'].isin(negative_emotions)]['word'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh2dN7Ul3ysC"
   },
   "source": [
    "### Sample from dictionary\n",
    "We can look at an excerpt of the positive words contained in the dictionary.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730729590537,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "_Xqz4inW3ysC",
    "outputId": "16a95cdd-bdac-4c14-fdc5-9d393217ed07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abacus', 'abandonment', 'abba', 'abbot', 'abduction', 'ability',\n",
       "       'abovementioned', 'abrupt', 'absolute', 'absolution'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsuBrvzo3ysC"
   },
   "source": [
    "### Stem the positive and negative dictionaries\n",
    "The tokens in the dictionary aren't stemmed per default. Since we stemmed the tokens in our data, we also stem the positive and negative words in the dictionary.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sbXXfmYi3ysC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abacu',\n",
       " 'abandon',\n",
       " 'abba',\n",
       " 'abbot',\n",
       " 'abduct',\n",
       " 'abil',\n",
       " 'abovement',\n",
       " 'abrupt',\n",
       " 'absolut',\n",
       " 'absolut']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Porter stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# Stem the words in each list\n",
    "positive_words_stemmed = [stemmer.stem(word) for word in positive_words]\n",
    "negative_words_stemmed = [stemmer.stem(word) for word in negative_words]\n",
    "\n",
    "\n",
    "positive_words_stemmed[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDM4Bx2y3ysC"
   },
   "source": [
    "### Look-up remaining tokens in NRC dictionary and transform results to data frame\n",
    "If you want to perform the analysis with the unstemmed tokens you can copy the needed code parts to the summary section and use the unstemmed reviews as input and remove the stemming from the preprocessing to use the unstemmed tokens. Additionally you will have to set stemmed_dict = False.\n",
    "\n",
    "Which procedure yields more accurate results and what do you believe to be the reason for the outcome?\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1730729591315,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "MWKuN0z5Zw35",
    "outputId": "b5fc1872-0911-4e4c-ce6b-dd132aef9421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Stemmed Dictionary:\n",
      "      positive_count  negative_count\n",
      "0                 53              39\n",
      "1                 26               5\n",
      "2                 57              48\n",
      "3                 51              26\n",
      "4                 51              39\n",
      "...              ...             ...\n",
      "4995              25              12\n",
      "4996              25              12\n",
      "4997              27              16\n",
      "4998              17              11\n",
      "4999              22               8\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with both stemmed and unstemmed words for sentiment analysis\n",
    "sentiment_dict = {\n",
    "    'positive': list(positive_words),\n",
    "    'negative': list(negative_words),\n",
    "    'positive_stemmed': positive_words_stemmed,\n",
    "    'negative_stemmed': negative_words_stemmed\n",
    "}\n",
    "\n",
    "def sentiment_lookup(tokens, sentiment_dict, stemmed_dict=True):\n",
    "    if stemmed_dict:\n",
    "        # Use stemmed versions of the dictionary\n",
    "        positive_words = sentiment_dict['positive_stemmed']\n",
    "        negative_words = sentiment_dict['negative_stemmed']\n",
    "    else:\n",
    "        # Use original versions of the dictionary\n",
    "        positive_words = sentiment_dict['positive']\n",
    "        negative_words = sentiment_dict['negative']\n",
    "    \n",
    "    # Count positive and negative word matches\n",
    "    positive_count = sum(1 for token in tokens if token in positive_words)\n",
    "    negative_count = sum(1 for token in tokens if token in negative_words)\n",
    "    \n",
    "    return positive_count, negative_count\n",
    "\n",
    "#Use the preprocessed reviews as input, which we saved as \"tokens\" in our data, to perform the lookup\n",
    "reviews_toks_stemmed = reviews['tokens']\n",
    "\n",
    "# Perform lookup with stemmed dictionary\n",
    "results = [sentiment_lookup(review, sentiment_dict, stemmed_dict=True) for review in reviews_toks_stemmed]\n",
    "df_results = pd.DataFrame(results, columns=['positive_count', 'negative_count'])\n",
    "print(\"Results with Stemmed Dictionary:\")\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPHK0id3ysC"
   },
   "source": [
    "### Calculate overall sentiment score\n",
    "After looking up the sentiment for the remaining tokens of each text we can now aggregate them by simply subtracting the number of negative words from the number of positive words found.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.613800</td>\n",
       "      <td>19.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.080918</td>\n",
       "      <td>15.816597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.000000</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       positive_count  negative_count\n",
       "count     5000.000000     5000.000000\n",
       "mean        31.613800       19.301800\n",
       "std         24.080918       15.816597\n",
       "min          0.000000        0.000000\n",
       "25%         16.000000        9.000000\n",
       "50%         24.000000       15.000000\n",
       "75%         39.000000       24.000000\n",
       "max        334.000000      245.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a quick overview of the positive and negative results\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1730730262165,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "RwzHC64S3ysD",
    "outputId": "599d06d9-ae47-4069-dc1e-f3a3eaf09721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results DataFrame:\n",
      "      positive_count  negative_count  sentiment_algo_score\n",
      "0                 53              39                    14\n",
      "1                 26               5                    21\n",
      "2                 57              48                     9\n",
      "3                 51              26                    25\n",
      "4                 51              39                    12\n",
      "...              ...             ...                   ...\n",
      "4995              25              12                    13\n",
      "4996              25              12                    13\n",
      "4997              27              16                    11\n",
      "4998              17              11                     6\n",
      "4999              22               8                    14\n",
      "\n",
      "[5000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate sentiment algorithm score (positive - negative)\n",
    "df_results['sentiment_algo_score'] = df_results['positive_count'] - df_results['negative_count']\n",
    "\n",
    "# Print the results with sentiment scores\n",
    "print(\"Results DataFrame:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eyV-djH3ysD"
   },
   "source": [
    "### Scale sentiment score by number of emotional words in a review\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "_aLRPXe-3ysD",
    "outputId": "f1a27fc6-c80b-4491-a735-33c4bd02a345"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean        0.252911\n",
       "std         0.190534\n",
       "min        -1.000000\n",
       "25%         0.131843\n",
       "50%         0.250000\n",
       "75%         0.373134\n",
       "max         1.000000\n",
       "Name: sentiment_algo_scaled, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['sentiment_algo_scaled'] = df_results['sentiment_algo_score'] / (df_results['positive_count'] + df_results['negative_count'])\n",
    "df_results.fillna({'sentiment_algo_scaled': 0}, inplace=True)\n",
    "df_results['sentiment_algo_scaled'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcVW_KkH3ysD"
   },
   "source": [
    "### Calculate binary sentiment label\n",
    "Similarly to classification we still have to decide which label to assign to each instance because until now we only have calculated their sentiment scores. Because we scaled the scores in the previous cell we can infer that scores greater than 0 indicate a positive sentiment and otherwise a negative sentiment.\n",
    "\n",
    "Our model predicts 685 negative reviews and 4315 positive reviews.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "dEVHjnla3ysD",
    "outputId": "b29c45c8-84fe-4938-aa61-c464e4573d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    4532\n",
       "negative     468\n",
       "Name: sentiment_algo_binary, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['sentiment_algo_binary'] = ['positive' if x > 0 else 'negative' for x in df_results['sentiment_algo_scaled']]\n",
    "df_results['sentiment_algo_binary'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXdANuDp3ysD"
   },
   "source": [
    "### Show distribution of human sentiment lables\n",
    "As a reference we can also display the ground truth distribution of positive and negative reviews, which is represented through the column \"sentiment_human\" in our dataset. We can see that our model predicts a lot more positive reviews than contained in the dataset. (What could be a possible reason?)\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730729591787,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "0psY1-8V3ysD",
    "outputId": "d33b7c0c-c632-457e-f79f-743eaa52af58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2517\n",
       "negative    2483\n",
       "Name: sentiment_human, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['sentiment_human'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xni3qqmP3ysD"
   },
   "source": [
    "### Evaluate accuracy with human sentiment lables as ground truth\n",
    "Since the task at hand is classification (the only difference lies in the type of input data) we can evaluate our model in the same way as we did before.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6gmmY_rWfMAn"
   },
   "outputs": [],
   "source": [
    "reviews_df_sent, results_df_bin = pd.DataFrame(reviews['sentiment_human']), pd.DataFrame(df_results['sentiment_algo_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1730731412830,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "s53MwZN1aVwB",
    "outputId": "5e4fff19-61f2-41cd-b5bd-ecb5f196a3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (NRC): 0.557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1548ebf40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Compute accuracy\n",
    "accuracy_nrc = accuracy_score(reviews_df_sent['sentiment_human'], results_df_bin['sentiment_algo_binary'])\n",
    "print(\"Accuracy (NRC):\", accuracy_nrc)\n",
    "\n",
    "#Compute confusion matrix of human sentiment and algorithm sentiment\n",
    "ConfusionMatrixDisplay.from_predictions(reviews_df_sent['sentiment_human'], results_df_bin['sentiment_algo_binary'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ytrSOQR3ysD"
   },
   "source": [
    "## Vader Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vader Dictionary\n",
    "\n",
    "We install the Vader package first, as it is not natively supported on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5682,
     "status": "ok",
     "timestamp": 1730729597822,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "i6LU0W3e3ysD",
    "outputId": "15d7ffe6-49e5-482a-bfbe-e1b83f19aa74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/katharinabrennig/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Installing the Vader Package \n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the Vader (Valence Aware Dictionary and Sentiment Reasoner) model. It is a rule-based sentiment analysis tool that is specifically designed for analyzing social media texts. Vader is a pre-trained sentiment analysis model that provides a sentiment score for a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4Zh_DIdX3ysD"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "vader_sa_classifier = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Similar as before we tokenize the texts first, remove stopwords, and punctuation. The difference to before is that we do not perform stemming. Further we return the preprocessed tokens as a whole string and not a list of tokens as Vader expects a complete string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Get the list of stopwords in English\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "\n",
    "    # Remove punctuation\n",
    "    filtered_tokens_nopunct = [token for token in filtered_tokens if token not in string.punctuation]\n",
    "\n",
    "    return \" \".join(filtered_tokens_nopunct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the preprocessing on the text and save the preprocessed text in a new column called 'text_prep'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 44349,
     "status": "ok",
     "timestamp": 1730737144570,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "URaLhCa93ysD"
   },
   "outputs": [],
   "source": [
    "reviews['text_prep'] = reviews['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataunderstanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a closer look how the prepared text for a positive and negative review looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1730737157910,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "FRdjZVLJ3ysG",
    "outputId": "524a508a-a586-4a9e-de66-eef000a1c1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stuff going moment MJ 've started listening music watching odd documentary watched Wiz watched Moonwalker Maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent Moonwalker part biography part feature film remember going see cinema originally released subtle messages MJ 's feeling towards press also obvious message drugs bad m'kay. br br Visually impressive course Michael Jackson unless remotely like MJ anyway going hate find boring may call MJ egotist consenting making movie MJ fans would say made fans true really nice him. br br actual feature film bit finally starts 20 minutes excluding Smooth Criminal sequence Joe Pesci convincing psychopathic powerful drug lord wants MJ dead bad beyond MJ overheard plans Nah Joe Pesci 's character ranted wanted people know supplying drugs etc dunno maybe hates MJ 's music. br br Lots cool things like MJ turning car robot whole Speed Demon sequence Also director must patience saint came filming kiddy Bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene. br br Bottom line movie people like MJ one level another think people stay away try give wholesome message ironically MJ 's bestest buddy movie girl Michael Jackson truly one talented people ever grace planet guilty Well attention 've gave subject .... hmmm well n't know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter\n",
      "===\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(reviews.iloc[0]['text_prep'])\n",
    "print(\"===\")\n",
    "print(reviews.iloc[0]['sentiment_human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1730737162882,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "bRcRB5a63ysG",
    "outputId": "1b3f16e9-d2d8-4e56-f7f1-003405288120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film starts manager Nicholas Bell giving welcome investors Robert Carradine Primal Park secret project mutating primal animal using fossilized DNA like Jurassik Park scientists resurrect one nature 's fearsome predators Sabretooth tiger Smilodon Scientific ambition turns deadly however high voltage fence opened creature escape begins savagely stalking prey human visitors tourists scientific.Meanwhile youngsters enter restricted area security center attacked pack large pre-historical animals deadlier bigger addition security agent Stacy Haiduk mate Brian Wimmer fight hardly carnivorous Smilodons Sabretooths course real star stars astounding terrifyingly though convincing giant animals savagely stalking prey group run afoul fight one nature 's fearsome predators Furthermore third Sabretooth dangerous slow stalks victims. br br movie delivers goods lots blood gore beheading hair-raising chills full scares Sabretooths appear mediocre special effects.The story provides exciting stirring entertainment results quite boring .The giant animals majority made computer generator seem totally lousy .Middling performances though players reacting appropriately becoming food.Actors give vigorously physical performances dodging beasts running bound leaps dangling walls packs ridiculous final deadly scene small kids realistic gory violent attack scenes films Sabretooths Smilodon following Sabretooth 2002 James R Hickox Vanessa Angel David Keith John Rhys Davies much better 10.000 BC 2006 Roland Emmerich Steven Strait Cliff Curtis Camilla Belle motion picture filled bloody moments badly directed George Miller originality takes many elements previous films Miller Australian director usually working television Tidal wave Journey center earth many others occasionally cinema man Snowy river Zeus Roxanne Robinson Crusoe Rating average bottom barrel\n",
      "===\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "print(reviews.iloc[2]['text_prep'])\n",
    "print(\"===\")\n",
    "print(reviews.iloc[2]['sentiment_human'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the reviews\n",
    "\n",
    "Running the code below will give us an overview of how the human sentiment is distributed among the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "executionInfo": {
     "elapsed": 1494,
     "status": "ok",
     "timestamp": 1730737169684,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "eqYWU6o73ysG",
    "outputId": "06d1010f-712e-473a-b247-93a3627e8d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment_human', ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data=reviews, x=\"sentiment_human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730737169684,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "A8Bp6PvJ3ysH",
    "outputId": "284888e7-a9e5-49ce-b988-3f1419b432ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2517\n",
       "negative    2483\n",
       "Name: sentiment_human, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count absolute human sentiment for the reviews\n",
    "reviews[\"sentiment_human\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730737170577,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "KlQJV7Rn3ysH",
    "outputId": "8147caa7-7bd5-4bdd-81f1-1e2fc26a8fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.5034\n",
       "negative    0.4966\n",
       "Name: sentiment_human, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the relative human sentiment for the reviews\n",
    "reviews[\"sentiment_human\"].value_counts()/reviews.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the sentiment with the model on the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below retrieves preprocessed text (text_prep) from the data (X) and uses VADER's polarity_scores to compute sentiment scores (neg, neu, pos, compound) for one specific review. This will give us some insights on how VADER works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1730737179752,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "zSL9weKa3ysH",
    "outputId": "a0e30bc4-1076-4d68-edd3-fc241d650dcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'' Classic War Worlds\\ '' Timothy Hines entertaining film obviously goes great effort lengths faithfully recreate H. G. Wells classic book Mr. Hines succeeds watched film appreciated fact standard predictable Hollywood fare comes every year e.g Spielberg version Tom Cruise slightest resemblance book Obviously everyone looks different things movie envision amateur '' critics\\ '' look criticize everything Others rate movie important bases like entertained people never agree '' critics\\ '' enjoyed effort Mr. Hines put faithful H.G Wells classic novel found entertaining made easy overlook '' critics\\ '' perceive shortcomings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.104, 'neu': 0.55, 'pos': 0.347, 'compound': 0.9808}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reviews.iloc[1][\"text_prep\"])\n",
    "vader_sa_classifier.polarity_scores(reviews.iloc[1][\"text_prep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "#print the human sentiment for this review\n",
    "print(reviews.iloc[1][\"sentiment_human\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below now predicts the sentiment based reviews. Therefore the code iterates through each row of the dataset (X), calculates sentiment scores using VADER's polarity_scores on the preprocessed text (text_prep), classifies the sentiment as \"positive\" (if compound > 0) or \"negative\" otherwise, and stores the results in the y_vader list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 10116,
     "status": "ok",
     "timestamp": 1730737195891,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "O2Y5IPYq3ysH"
   },
   "outputs": [],
   "source": [
    "sentiment_vader = []\n",
    "for index, row in reviews.iterrows():\n",
    "    vs = vader_sa_classifier.polarity_scores(row[\"text_prep\"])\n",
    "    if vs[\"compound\"] > 0:\n",
    "      sentiment = \"positive\"\n",
    "    else:\n",
    "      sentiment = \"negative\"\n",
    "    sentiment_vader.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment Vader: 1534\n",
      "Positive Sentiment Vader: 3466\n"
     ]
    }
   ],
   "source": [
    "#count values for positive and negative sentiment\n",
    "negative_sentiment_vader=sentiment_vader.count(\"negative\")\n",
    "positive_sentiment_vader=sentiment_vader.count(\"positive\")\n",
    "print(\"Negative Sentiment Vader:\",negative_sentiment_vader)\n",
    "print(\"Positive Sentiment Vader:\",positive_sentiment_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1730737204339,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "tU3umkuC3ysH",
    "outputId": "bd126139-cc2b-4e57-aeee-a1cde0dfcea0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_vader[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy with human sentiment lables as ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the task at hand is classification (the only difference lies in the type of input data) we can evaluate our model in the same way as we did before.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1730737206204,
     "user": {
      "displayName": "Arthur S",
      "userId": "06175255907682516412"
     },
     "user_tz": -60
    },
    "id": "p-5dhNB23ysH",
    "outputId": "10bba03f-2996-4ad5-ede3-b63c28ea53f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Vader): 0.687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15f57ddc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "accuracy_vader = accuracy_score(reviews['sentiment_human'], sentiment_vader)\n",
    "print(\"Accuracy (Vader):\", accuracy_vader)\n",
    "\n",
    "# Create the confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(reviews['sentiment_human'], sentiment_vader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "So to sum it up let us have a look what we did in this week's tutorial:\n",
    "\n",
    "* First, we had a look at the necessary preprocessing steps (tokenization, unwanted character removal, stemming, stopword removal) needed to transform text into a more structured form.\n",
    "* Secondly we performed dictionary-based sentiment analysis where we looked up the sentiment of each token in a dict and aggregated the scores in order to decide whether a review is positive or negative.\n",
    "* Lastly we used known evaluation metrics for classification to evaluate our model.\n",
    "* Additionaly we had a little excursion of using the pre-trained VADER model and evaluating the performance.\n",
    "\n",
    "\n",
    "You can use the cell below to perform and evaluate different sentiment analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Code here!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
