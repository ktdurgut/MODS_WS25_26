{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C8DOFAFKmTZ7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzQ5YsjRmZ-y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "reviews = pd.read_csv(\"https://raw.githubusercontent.com/kbrennig/MODS_WS25_26/refs/heads/main/data/imdb_sample.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews['sentiment_positive'] = np.where(reviews['sentiment_human'] == 'positive', 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = reviews.drop(columns=['id','sentiment_human','sentiment_positive'])\n",
        "y = reviews['sentiment_positive']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqxyC15BmlX6",
        "outputId": "24778960-8468-4b44-e369-e89b03aeb359"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "    filtered_tokens = [token for token in lemmatized_tokens if token.lower() not in stopwords]\n",
        "\n",
        "    filtered_tokens_nopunct = [re.sub(r'[^\\w\\s]', '', token) for token in filtered_tokens if token]\n",
        "\n",
        "    return filtered_tokens_nopunct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cu9wGUwwntuI"
      },
      "outputs": [],
      "source": [
        "X_train['tokens'] = X_train['text'].apply(preprocess)\n",
        "X_test['tokens'] = X_test['text'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "87DBC0V5oxIF"
      },
      "outputs": [],
      "source": [
        "X_train['tokens'] = X_train['tokens'].apply(lambda tokens: [token for token in tokens if token not in {'movie', 'film'}])\n",
        "X_test['tokens'] = X_test['tokens'].apply(lambda tokens: [token for token in tokens if token not in {'movie', 'film'}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nzlz0kG8pbct"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(X_train['tokens'])\n",
        "dictionary.filter_extremes(no_below=5)\n",
        "\n",
        "corpus_train = [dictionary.doc2bow(text) for text in X_train['tokens']]\n",
        "corpus_test = [dictionary.doc2bow(text) for text in X_test['tokens']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models.ldamodel import LdaModel\n",
        "\n",
        "k=12\n",
        "model_12 = LdaModel(corpus=corpus_train, num_topics=k, id2word = dictionary, iterations=100, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JVaVR1zoqTjz"
      },
      "outputs": [],
      "source": [
        "def get_document_topic_distribution(model, corpus):\n",
        "    return pd.DataFrame(\n",
        "        [\n",
        "            [prob for _, prob in model.get_document_topics(doc, minimum_probability=0)]\n",
        "            for doc in corpus\n",
        "        ],\n",
        "        columns=[f'Topic{i+1}' for i in range(model.num_topics)]\n",
        "    )\n",
        "\n",
        "train_topic_distributions = get_document_topic_distribution(model_12, corpus_train)\n",
        "test_topic_distributions = get_document_topic_distribution(model_12, corpus_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GWt13HE9rQ7H"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_topicmodel = RandomForestClassifier(random_state=42).fit(train_topic_distributions, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "ZsAuEwh_rUyw",
        "outputId": "65e13ff0-fc96-4003-e890-b542f3befbe4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions_testset_rf_topicmodel = rf_topicmodel.predict_proba(test_topic_distributions)[:, 1]\n",
        "predictions_testset_rf_topicmodel_binary = np.where(predictions_testset_rf_topicmodel > 0.5, 1, 0)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, predictions_testset_rf_topicmodel_binary)\n",
        "print(\"Accuracy (Random Forests):\", accuracy_rf)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions_testset_rf_topicmodel_binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "Cv2D8Sw_rZiY",
        "outputId": "0d4c40da-cdbb-4f46-981f-9e0d271db108"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "auc_score = roc_auc_score(y_test, predictions_testset_rf_topicmodel)\n",
        "print(\"AUC Score:\", auc_score)\n",
        "\n",
        "RocCurveDisplay.from_predictions(y_test, predictions_testset_rf_topicmodel, plot_chance_level=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
